{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import of libraries**"
      ],
      "metadata": {
        "id": "h6JqVEYqr-Ep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "OQMxTR3qUEJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afdb969e-45d1-4bab-98d3-af16deaab88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import string\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import cmudict\n",
        "import nltk\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('cmudict')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to Drive**"
      ],
      "metadata": {
        "id": "JnJ9tBdxF6XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rXMg0jyxFb_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab2cfea-15fb-467a-cd6b-3bc6f780e2c8"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading a Input-File and Output-File**"
      ],
      "metadata": {
        "id": "gDJ2warJsEYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = pd.read_excel(\"/content/drive/MyDrive/20211030 Test Assignment/Input.xlsx\")\n",
        "output_file = pd.read_excel(\"/content/drive/MyDrive/20211030 Test Assignment/Output Data Structure.xlsx\")"
      ],
      "metadata": {
        "id": "R2FhkM6yUKGV"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code can be used to scrape and save it as file**"
      ],
      "metadata": {
        "id": "edWLahuReFkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''new_folder_path = '/content/scraped_data'\n",
        "\n",
        "# Check if the folder already exists, and if not, create it\n",
        "if not os.path.exists(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n",
        "    print(f\"Folder '{new_folder_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Folder '{new_folder_path}' already exists.\")'''\n",
        "\n",
        "\n",
        "\n",
        "'''not_found_urls = []\n",
        "for i in tqdm(range(len(input_file['URL']))):\n",
        "  url = input_file['URL'][i]\n",
        "  # Send a request to the URL and get the HTML content\n",
        "  response = requests.get(url)\n",
        "  soup = bs(response.content, 'html.parser')\n",
        "  try:\n",
        "    try:\n",
        "      # Find the article name\n",
        "      article_name = soup.find('h1').text.strip()\n",
        "\n",
        "      # Find the article text\n",
        "      article_text = ''\n",
        "      article_content = soup.find('div', class_=\"td-post-content\")\n",
        "      if article_content:\n",
        "          paragraphs = article_content.find_all('p')\n",
        "          article_text = ''.join(p.get_text() for p in paragraphs)\n",
        "\n",
        "      if article_name and article_text:\n",
        "        # Create a text file with the article name as the filename\n",
        "        file_name = f\"{article_name}.txt\"\n",
        "        file_path = os.path.join(folder_name, file_name)\n",
        "\n",
        "        # Write the article text to the file\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(article_text)\n",
        "    except:\n",
        "      # Find the article name\n",
        "      article_name = soup.find('h1').get_text().strip()\n",
        "\n",
        "      # Find the article text\n",
        "      article_text = ''\n",
        "      article_content = soup.find('div', class_=\"td-post-content tagdiv-type\")\n",
        "      if article_content:\n",
        "          paragraphs = article_content.find_all('p')\n",
        "          article_text = ''.join(p.get_text() for p in paragraphs)\n",
        "\n",
        "      if article_name and article_text:\n",
        "        # Create a text file with the article name as the filename\n",
        "        file_name = f\"{article_name}.txt\"\n",
        "        file_path = os.path.join(folder_name, file_name)\n",
        "\n",
        "        # Write the article text to the file\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(article_text)\n",
        "  except:\n",
        "    not_found_urls.append(i)\n",
        "    continue'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "BJHh9wk4dxjR",
        "outputId": "b14c1c21-a6af-4a28-b71e-0d609c05a06c"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not_found_urls = []\\nfor i in tqdm(range(len(input_file[\\'URL\\']))):\\n  url = input_file[\\'URL\\'][i]\\n  # Send a request to the URL and get the HTML content\\n  response = requests.get(url)\\n  soup = bs(response.content, \\'html.parser\\')\\n  try:\\n    try:\\n      # Find the article name\\n      article_name = soup.find(\\'h1\\').text.strip()\\n\\n      # Find the article text\\n      article_text = \\'\\'\\n      article_content = soup.find(\\'div\\', class_=\"td-post-content\")\\n      if article_content:\\n          paragraphs = article_content.find_all(\\'p\\')\\n          article_text = \\'\\'.join(p.get_text() for p in paragraphs)\\n\\n      if article_name and article_text:\\n        # Create a text file with the article name as the filename\\n        file_name = f\"{article_name}.txt\"\\n        file_path = os.path.join(folder_name, file_name)\\n\\n        # Write the article text to the file\\n        with open(file_path, \\'w\\') as file:\\n            file.write(article_text)\\n    except:\\n      # Find the article name\\n      article_name = soup.find(\\'h1\\').get_text().strip()\\n\\n      # Find the article text\\n      article_text = \\'\\'\\n      article_content = soup.find(\\'div\\', class_=\"td-post-content tagdiv-type\")\\n      if article_content:\\n          paragraphs = article_content.find_all(\\'p\\')\\n          article_text = \\'\\'.join(p.get_text() for p in paragraphs)\\n\\n      if article_name and article_text:\\n        # Create a text file with the article name as the filename\\n        file_name = f\"{article_name}.txt\"\\n        file_path = os.path.join(folder_name, file_name)\\n\\n        # Write the article text to the file\\n        with open(file_path, \\'w\\') as file:\\n            file.write(article_text)\\n  except:\\n    not_found_urls.append(i)\\n    continue'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Implementation for Web-Scrapping and formation of text-file**"
      ],
      "metadata": {
        "id": "NU1xUP-xsS41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_data(url):\n",
        "  response = requests.get(url)\n",
        "  soup = bs(response.content, 'html.parser')\n",
        "  try:\n",
        "    try:\n",
        "      # Find the article name\n",
        "      article_name = soup.find('h1').text.strip()\n",
        "\n",
        "      # Find the article text\n",
        "      article_text = ''\n",
        "      article_content = soup.find('div', class_=\"td-post-content\")\n",
        "      if article_content:\n",
        "          paragraphs = article_content.find_all('p')\n",
        "          article_text = ''.join(p.get_text() for p in paragraphs)\n",
        "\n",
        "      text = article_text\n",
        "    except:\n",
        "      # Find the article name\n",
        "      article_name = soup.find('h1').get_text().strip()\n",
        "\n",
        "      # Find the article text\n",
        "      article_text = ''\n",
        "      article_content = soup.find('div', class_=\"td-post-content tagdiv-type\")\n",
        "      if article_content:\n",
        "          paragraphs = article_content.find_all('p')\n",
        "          article_text = ''.join(p.get_text() for p in paragraphs)\n",
        "\n",
        "      text = article_text\n",
        "  except:\n",
        "    text = \"error 404: page not found\"\n",
        "  return text"
      ],
      "metadata": {
        "id": "pkVVOyqMUJ8p"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop_words extraction**\n"
      ],
      "metadata": {
        "id": "9tEwSYwVL5TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_auditors = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Auditor.txt','r') as f:\n",
        "  text = f.read()\n",
        "stop_words_auditors = text.split()"
      ],
      "metadata": {
        "id": "lVARPb4qUJzi"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_currency = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Currencies.txt','r',encoding='utf-8',errors='ignore') as f:\n",
        "  text = f.read()\n",
        "stop_words_currency = text.split()\n",
        "\n",
        "for i in stop_words_currency:\n",
        "  if i==\"|\":\n",
        "    stop_words_currency.remove(i)"
      ],
      "metadata": {
        "id": "i4e1Br0JRneO"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_date = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_DatesandNumbers.txt','r') as f:\n",
        "  text = f.read()\n",
        "stop_words_date  = text.split()\n",
        "\n",
        "for i in stop_words_date:\n",
        "  if i==\"|\":\n",
        "    stop_words_date.remove(i)"
      ],
      "metadata": {
        "id": "RXYMYTz4GyvZ"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_generic = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Generic.txt','r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "stop_words_generic = text.split()"
      ],
      "metadata": {
        "id": "wzgFra3ZNZTg"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_genericlong = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_GenericLong.txt','r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "stop_words_genericlong = text.split()"
      ],
      "metadata": {
        "id": "lJCCwGGxN7UF"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_geographic = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Geographic.txt','r') as f:\n",
        "  text = f.read()\n",
        "stop_words_geographic = text.split()\n",
        "\n",
        "for i in stop_words_geographic:\n",
        "  if i==\"|\":\n",
        "    stop_words_geographic.remove(i)\n"
      ],
      "metadata": {
        "id": "GKsn9vWiOT6g"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_names = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Names.txt','r') as f:\n",
        "  text = f.read()\n",
        "stop_words_names = text.split()\n",
        "\n",
        "stop_words_names = stop_words_names[0:1] + stop_words_names[9:]"
      ],
      "metadata": {
        "id": "EnFIf5FJPNDS"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stop_words_auditors + stop_words_currency + stop_words_date + stop_words_generic + stop_words_genericlong + stop_words_geographic + stop_words_names + ['\"']"
      ],
      "metadata": {
        "id": "3uzVUn30eimB"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extraction of positive and negative words**"
      ],
      "metadata": {
        "id": "oJincWQ1kLQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_words = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/MasterDictionary/positive-words.txt','r') as f:\n",
        "  text = f.read()\n",
        "positive_words = text.split()"
      ],
      "metadata": {
        "id": "ocOqzY-HkVq9"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_words = []\n",
        "\n",
        "with open('/content/drive/MyDrive/20211030 Test Assignment/MasterDictionary/negative-words.txt','r',errors='ignore') as f:\n",
        "  text = f.read()\n",
        "negative_words = text.split()"
      ],
      "metadata": {
        "id": "o7bZBiDEkVnZ"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Preprocessing & Tokenization**"
      ],
      "metadata": {
        "id": "xR44aMo0fO0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenize the text into individual words\n",
        "    tokens = word_tokenize(text)\n",
        "    # removing double inverted comma\n",
        "    text = text.replace('‘', '').replace('“', '')\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "    # Convert to lowercase\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "9wB-YtALggkr"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def syllable_count(word):\n",
        "    vowels = \"aeiouAEIOU\"\n",
        "    count = 0\n",
        "    in_vowel_group = False\n",
        "\n",
        "    for char in word:\n",
        "        if char in vowels:\n",
        "            if not in_vowel_group:\n",
        "                count += 1\n",
        "                in_vowel_group = True\n",
        "        else:\n",
        "            in_vowel_group = False\n",
        "\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "\n",
        "    if count == 0:\n",
        "        count = 1\n",
        "\n",
        "    return count"
      ],
      "metadata": {
        "id": "HD3azmDnw2v9"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Positive and Negative Word**"
      ],
      "metadata": {
        "id": "5lryOxzY-QIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positivewords = set(positive_words)\n",
        "negativewords = set(negative_words)"
      ],
      "metadata": {
        "id": "qwlqobotsyn_"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment Analysis**\n",
        "- In this part we will apply the sentiment analysis on text files we extrated after appling the preprocessing and tokenization step.Also save respective scores of particular url in output file"
      ],
      "metadata": {
        "id": "RlHDUXIXlJGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(input_file.shape[0])):\n",
        "  #taking the url from the input file\n",
        "  url = input_file.at[i,\"URL\"]\n",
        "\n",
        "\n",
        "  #scrapping data from the url\n",
        "  text = scrape_data(url)\n",
        "\n",
        "\n",
        "  # tokenizing and preprocessing the text with above method\n",
        "  tokenized_text_data = preprocess_text(text)\n",
        "\n",
        "\n",
        "  # Calculate additional metrics\n",
        "  positive_score = sum(tokenized_text_data.count(word) for word in positivewords)\n",
        "  negative_score = sum(tokenized_text_data.count(word) for word in negativewords)\n",
        "  polarity_score =  (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
        "  subjectivity_score = (positive_score + negative_score)/ ((len(tokenized_text_data)) + 0.000001)\n",
        "\n",
        "  #calculating average sentence length and fog index\n",
        "  avg_sentence_len = len(tokenized_text_data) / len(sent_tokenize(text))\n",
        "  percentage_complex_words = 100 * len([word for word in tokenized_text_data if syllable_count(word) > 2]) / len(tokenized_text_data)\n",
        "  fog_index = 0.4 * (avg_sentence_len + percentage_complex_words)\n",
        "  word_count = len(tokenized_text_data)\n",
        "\n",
        "\n",
        "  #average number of word per sentence\n",
        "  sentences = sent_tokenize(text)\n",
        "  total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
        "  total_sentences = len(sentences)\n",
        "  avg_num_word_per_sen = total_words/total_sentences\n",
        "\n",
        "\n",
        "  #complex word count\n",
        "  complex_word_count = len([word for word in tokenized_text_data if len(word) > 2])\n",
        "  syllables_per_word = sum(len(word) for word in tokenized_text_data) / word_count\n",
        "\n",
        "\n",
        "  # Personal pronouns (you may need to customize this based on your specific use case)\n",
        "  personal_pronouns = [\"i\", \"ours\", \"we\", \"my\",\"us\",\"he\",\"she\",\"\"]\n",
        "  personal_pronoun_count = len([word for word in tokenized_text_data if word in personal_pronouns])\n",
        "\n",
        "\n",
        "  # Calculate average word length\n",
        "  total_word_length = sum(len(word) for word in tokenized_text_data)\n",
        "  avg_word_length = total_word_length / word_count\n",
        "\n",
        "\n",
        "  #filling values in the dataframe\n",
        "  output_file.at[i,'POSITIVE SCORE'] = positive_score\n",
        "  output_file.at[i,'NEGATIVE SCORE'] = negative_score\n",
        "  output_file.at[i,'POLARITY SCORE'] = polarity_score\n",
        "  output_file.at[i,'SUBJECTIVITY SCORE'] = subjectivity_score\n",
        "  output_file.at[i,'AVG SENTENCE LENGTH'] = avg_sentence_len\n",
        "  output_file.at[i,'PERCENTAGE OF COMPLEX WORDS'] = percentage_complex_words\n",
        "  output_file.at[i,'FOG INDEX'] = fog_index\n",
        "  output_file.at[i,'AVG NUMBER OF WORDS PER SENTENCE'] = avg_num_word_per_sen\n",
        "  output_file.at[i,'COMPLEX WORD COUNT'] = complex_word_count\n",
        "  output_file.at[i,'WORD COUNT'] = word_count\n",
        "  output_file.at[i,'SYLLABLE PER WORD'] = syllables_per_word\n",
        "  output_file.at[i,'PERSONAL PRONOUNS'] = personal_pronoun_count\n",
        "  output_file.at[i,'AVG WORD LENGTH'] = avg_word_length"
      ],
      "metadata": {
        "id": "a5BLPiV_lIuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62db8d89-00ef-4f3b-9c79-9a93e81cd51e"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114/114 [01:59<00:00,  1.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "WekHmyTEbpKy",
        "outputId": "473b6f6a-604d-422a-b654-2c22a97a74b2"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     URL_ID                                                URL  \\\n",
              "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
              "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
              "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
              "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
              "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
              "..      ...                                                ...   \n",
              "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
              "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
              "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
              "112     149  https://insights.blackcoffer.com/business-anal...   \n",
              "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
              "\n",
              "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
              "0              65.0            31.0        0.354167            0.094303   \n",
              "1              57.0            36.0        0.225806            0.147152   \n",
              "2              65.0            37.0        0.274510            0.118056   \n",
              "3              62.0            22.0        0.476190            0.121563   \n",
              "4              56.0            23.0        0.417722            0.094611   \n",
              "..              ...             ...             ...                 ...   \n",
              "109            21.0            27.0       -0.125000            0.106195   \n",
              "110            35.0            12.0        0.489362            0.081739   \n",
              "111            26.0            46.0       -0.277778            0.120000   \n",
              "112            29.0             3.0        0.812500            0.113475   \n",
              "113            33.0            41.0       -0.108108            0.147705   \n",
              "\n",
              "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
              "0              19.207547                    41.257367  24.185966   \n",
              "1               9.432836                    34.018987  17.380729   \n",
              "2              12.895522                    42.824074  22.287839   \n",
              "3               9.213333                    31.837916  16.420500   \n",
              "4              12.651515                    34.610778  18.904917   \n",
              "..                   ...                          ...        ...   \n",
              "109            11.894737                    36.504425  19.359665   \n",
              "110            14.375000                    34.434783  19.523913   \n",
              "111             9.836066                    34.166667  17.601093   \n",
              "112            17.625000                    47.163121  25.915248   \n",
              "113             8.080645                    35.329341  17.363995   \n",
              "\n",
              "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
              "0                           36.716981               967.0      1018.0   \n",
              "1                           24.014925               580.0       632.0   \n",
              "2                           27.746269               835.0       864.0   \n",
              "3                           23.013333               639.0       691.0   \n",
              "4                           28.848485               791.0       835.0   \n",
              "..                                ...                 ...         ...   \n",
              "109                         25.236842               442.0       452.0   \n",
              "110                         30.075000               550.0       575.0   \n",
              "111                         20.442623               583.0       600.0   \n",
              "112                         37.375000               275.0       282.0   \n",
              "113                         18.145161               496.0       501.0   \n",
              "\n",
              "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
              "0             7.564833                0.0         7.564833  \n",
              "1             6.707278                0.0         6.707278  \n",
              "2             7.587963                0.0         7.587963  \n",
              "3             6.829233                0.0         6.829233  \n",
              "4             6.936527                0.0         6.936527  \n",
              "..                 ...                ...              ...  \n",
              "109           7.621681                0.0         7.621681  \n",
              "110           7.111304                0.0         7.111304  \n",
              "111           6.870000                0.0         6.870000  \n",
              "112           7.971631                0.0         7.971631  \n",
              "113           7.107784                0.0         7.107784  \n",
              "\n",
              "[114 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7b34ce59-36da-4c8e-82db-321143441019\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "      <th>POSITIVE SCORE</th>\n",
              "      <th>NEGATIVE SCORE</th>\n",
              "      <th>POLARITY SCORE</th>\n",
              "      <th>SUBJECTIVITY SCORE</th>\n",
              "      <th>AVG SENTENCE LENGTH</th>\n",
              "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
              "      <th>FOG INDEX</th>\n",
              "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
              "      <th>COMPLEX WORD COUNT</th>\n",
              "      <th>WORD COUNT</th>\n",
              "      <th>SYLLABLE PER WORD</th>\n",
              "      <th>PERSONAL PRONOUNS</th>\n",
              "      <th>AVG WORD LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.094303</td>\n",
              "      <td>19.207547</td>\n",
              "      <td>41.257367</td>\n",
              "      <td>24.185966</td>\n",
              "      <td>36.716981</td>\n",
              "      <td>967.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>7.564833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.564833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
              "      <td>57.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.147152</td>\n",
              "      <td>9.432836</td>\n",
              "      <td>34.018987</td>\n",
              "      <td>17.380729</td>\n",
              "      <td>24.014925</td>\n",
              "      <td>580.0</td>\n",
              "      <td>632.0</td>\n",
              "      <td>6.707278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.707278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.118056</td>\n",
              "      <td>12.895522</td>\n",
              "      <td>42.824074</td>\n",
              "      <td>22.287839</td>\n",
              "      <td>27.746269</td>\n",
              "      <td>835.0</td>\n",
              "      <td>864.0</td>\n",
              "      <td>7.587963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.587963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
              "      <td>62.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.121563</td>\n",
              "      <td>9.213333</td>\n",
              "      <td>31.837916</td>\n",
              "      <td>16.420500</td>\n",
              "      <td>23.013333</td>\n",
              "      <td>639.0</td>\n",
              "      <td>691.0</td>\n",
              "      <td>6.829233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.829233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
              "      <td>56.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.417722</td>\n",
              "      <td>0.094611</td>\n",
              "      <td>12.651515</td>\n",
              "      <td>34.610778</td>\n",
              "      <td>18.904917</td>\n",
              "      <td>28.848485</td>\n",
              "      <td>791.0</td>\n",
              "      <td>835.0</td>\n",
              "      <td>6.936527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.936527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>146</td>\n",
              "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.106195</td>\n",
              "      <td>11.894737</td>\n",
              "      <td>36.504425</td>\n",
              "      <td>19.359665</td>\n",
              "      <td>25.236842</td>\n",
              "      <td>442.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>7.621681</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.621681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>147</td>\n",
              "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
              "      <td>35.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.489362</td>\n",
              "      <td>0.081739</td>\n",
              "      <td>14.375000</td>\n",
              "      <td>34.434783</td>\n",
              "      <td>19.523913</td>\n",
              "      <td>30.075000</td>\n",
              "      <td>550.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>7.111304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.111304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>148</td>\n",
              "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>-0.277778</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>9.836066</td>\n",
              "      <td>34.166667</td>\n",
              "      <td>17.601093</td>\n",
              "      <td>20.442623</td>\n",
              "      <td>583.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>6.870000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>149</td>\n",
              "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.113475</td>\n",
              "      <td>17.625000</td>\n",
              "      <td>47.163121</td>\n",
              "      <td>25.915248</td>\n",
              "      <td>37.375000</td>\n",
              "      <td>275.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>7.971631</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.971631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>150</td>\n",
              "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>-0.108108</td>\n",
              "      <td>0.147705</td>\n",
              "      <td>8.080645</td>\n",
              "      <td>35.329341</td>\n",
              "      <td>17.363995</td>\n",
              "      <td>18.145161</td>\n",
              "      <td>496.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>7.107784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.107784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b34ce59-36da-4c8e-82db-321143441019')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1f459650-488b-4b7c-9c5b-0e0d190e5b5c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f459650-488b-4b7c-9c5b-0e0d190e5b5c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1f459650-488b-4b7c-9c5b-0e0d190e5b5c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b34ce59-36da-4c8e-82db-321143441019 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b34ce59-36da-4c8e-82db-321143441019');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exporting as Excel file**"
      ],
      "metadata": {
        "id": "ATVlHsoacsGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file.to_excel(\"output.xlsx\")"
      ],
      "metadata": {
        "id": "T16Bv7P9bzTD"
      },
      "execution_count": 342,
      "outputs": []
    }
  ]
}